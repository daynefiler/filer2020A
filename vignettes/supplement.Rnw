\documentclass{article}
\usepackage{fullpage}
\usepackage{mathtools}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{bm}
\usepackage{enumitem}
\usepackage{authblk}
\usepackage{rotating}
\usepackage{array}
\usepackage{colortbl}
\usepackage{siunitx}
\usepackage{authblk}
\sisetup{output-exponent-marker=\ensuremath{\mathrm{e}}}

%% Supplemental figure notation
\renewcommand\thefigure{S\arabic{figure}}
\renewcommand\thetable{S\arabic{table}}

\DeclareUnicodeCharacter{251C}{\mbox{\kern.23em
  \vrule height2.2exdepth1exwidth.4pt\vrule height2.2ptdepth-1.8ptwidth.23em}}
\DeclareUnicodeCharacter{2500}{\mbox{\vrule height2.2ptdepth-1.8ptwidth.5em}}
\DeclareUnicodeCharacter{2514}{\mbox{\kern.23em
  \vrule height2.2exdepth-1.8ptwidth.4pt\vrule height2.2ptdepth-1.8ptwidth.23em}}
\DeclareUnicodeCharacter{2052}{\textdiscount}

\setlength{\parindent}{0em}
\setlength{\parskip}{1ex}

\begin{document}

<<knitrSetup,echo=FALSE,results='hide',warning=FALSE,message=FALSE>>=
library(knitr)
knit_theme$set("bclear")
knitr::opts_chunk$set(fig.path = "figures-",
                      dev = "pdf",
                      fig.width = 5,
                      fig.height = 2.5,
                      fig.show = 'hide',
                      dev.args = list(pdf = list(pointsize = 8)),
                      background = "#F7F7F7",
                      warning = FALSE,
                      message = FALSE,
                      error = FALSE,
                      cache = TRUE,
                      results = 'hide')
@

\title{Pre-capture multiplexing provides additional power to detect copy number variation in exome sequencing: Supplemental Information}
\author[1,2]{Dayne L. Filer}
\author[1]{Fengshen Kuo}
\author[1]{Alicia T. Brandt}
\author[1]{Christian R. Tilley}
\author[1]{Piotr A. Mieczkowski}
\author[1]{Jonathan S. Berg}
\author[1,2,3]{Kimberly Robasky}
\author[1,4]{Yun Li}
\author[2]{Chris Bizon}
\author[2]{Jeffery L. Tilson}
\author[1,2]{Bradford C. Powell}
\author[1,2]{Darius M. Bost}
\author[2]{Clark D. Jeffries}
\author[1,2,5]{Kirk C. Wilhelmsen}
\affil[1]{Department of Genetics, UNC School of Medicine, Chapel Hill, NC}
\affil[2]{Renaissance Computing Institute, Chapel Hill, NC}
\affil[3]{UNC School of Information and Library Science, Chapel Hill, NC}
\affil[4]{Department of Biostatistics, UNC Gillings School of Global Public Health, Chapel Hill, NC}
\affil[5]{Department of Neurology, UNC School of Medicine, Chapel Hill, NC}

\date{}

\maketitle

\tableofcontents

\newpage
\section{Setup}

<<loadPackages,cache=FALSE>>=
library(filer2020A)
library(mcCNV)
library(eulerr)
library(dlfUtils)
library(parallel)
library(grid)
@

\section{Summary of data}

<<makePoolTbl, results='markup'>>=
data(subjectMeta)
poolTbl <- subjectMeta[ ,
                       .(N = .N,
                         medExon = round(median(medIntMolCount), 0),
                         medTotal = round(median(totalMolCount), 0),
                         minTotal = min(totalMolCount),
                         maxTotal = max(totalMolCount),
                         rsdTotal = sd(totalMolCount)/mean(totalMolCount)*100),
                       by = .(pool, capture, multiplexCapture)]
poolTbl[ , rsdTotal := round(rsdTotal, 1)]
poolTbl
@

\newpage
\section{Mean-variance relationship for multplexed versus independent capture}

To show the difference in independent and multiplexed captures, we randomly select pools of samples independently-captured using the same platform.
We then calculate interval statistics (mean, variance, etc.) across the pools.
<<makePools>>=
smplSubject <- function(poolName, n) {
  data(subjectMeta, envir = environment())
  subjectMeta[pool == poolName, sample(subject, n, replace = FALSE)]
}
set.seed(1234)
pools <- c(replicate(5, smplSubject("NCGENES", 16), simplify = FALSE))
names(pools) <- c(sprintf("randNCG_%d", 1:5))
pools <- c(pools,
           with(subjectMeta[pool != "NCGENES"], split(subject, pool)))
@

<<calcMeanVar>>=
## Calculate mean-variance by pool
mnvr <- mclapply(pools, subsetCounts, mc.cores = length(pools))
mnvr <- mclapply(mnvr, calcIntStats, mc.cores = length(mnvr))
for (i in seq_along(mnvr)) {
  mnvr[[i]][ , pool := names(mnvr)[i]]
}
mnvr <- rbindlist(mnvr)
setkey(mnvr, pool); setcolorder(mnvr)

## Estimate alpha0
alpha0 <- mclapply(pools, estAlpha0, mc.cores = length(pools))
@

<<alpha0>>=
a0tbl <- data.table(pool = names(alpha0),
                    a0 = sapply(alpha0, "[[", "a0"),
                    N = sapply(alpha0, "[[", "N"))
a0tbl[ , aMn := a0/N]
calcRange <- function(x) {
  subjectMeta[subject %in% x,
              .(mnCount = min(totalMolCount),
                mdCount = median(totalMolCount),
                mxCount = max(totalMolCount),
                rsCount = sd(totalMolCount)/mean(totalMolCount)*100)]
}
poolCts <- lapply(pools, calcRange)
poolCts <- lapply(names(poolCts), function(x) poolCts[[x]][ , pool := x])
poolCts <- rbindlist(poolCts)
a0tbl <- merge(a0tbl, poolCts)
a0tbl[ , mc := !grepl("IDT-IC|rand", pool)]
a0tbl[ , idt := grepl("IDT", pool)]
@

<<a0plot,fig.width=3.34,fig.height=3.34>>=
pltAlpha0(a0tbl)
@

\begin{figure}[H]
  \centering
  \includegraphics[]{figures-a0plot-1.pdf}
  \caption{manuscript figure}
\end{figure}

\newpage
<<mnVrPlot,fig.width=3.34,fig.height=3.34>>=
aglPools <- c(sprintf("randNCG_%d", 1:5), "Pool1", "Pool2", "WGS", "SMA1", "SMA2")
with(mnvr[pool %in% aglPools], {
  pltMnVrCont(dat = as.data.table(as.list(environment())),
              grpVec = factor(pool, levels = aglPools),
              colVec = c(rep('darkblue', 5), rep('darkorange', 5)),
              lgnd = FALSE)
})
addfiglab("A", units = "ndc")
legend(x = "center", lwd = 4, col = c('darkblue', 'darkorange'),
       c("AGL-IC", "AGL-MC"), bty = "n", cex = 0.75)
idtPools <- c("IDT-MC", "IDT-IC", "IDT-RR")
with(mnvr[pool %in% idtPools], {
  pltMnVrCont(dat = as.data.table(as.list(environment())),
              grpVec = factor(pool, levels = idtPools),
              colVec = c("darkorange", "darkblue", "darkorange"),
              lgnd = FALSE)
})
addfiglab("B")
legend(x = "center", lwd = 4, col = c('darkblue', 'darkorange'),
       c("IDT-IC", "IDT-MC"), bty = "n", cex = 0.75)

with(mnvr[pool %in% c("WGS", "IDT-RR")], {
  pltMnVrCont(dat = as.data.table(as.list(environment())),
              grpVec = factor(pool, levels = c("WGS", "IDT-RR")),
              colVec = c("darkblue", "darkorange"))
})
@

\begin{figure}[H]
  \centering
  \includegraphics[]{figures-mnVrPlot-1.pdf}%
  \includegraphics[]{figures-mnVrPlot-2.pdf}
  \caption{manuscript figure}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[]{figures-mnVrPlot-3.pdf}%
  \caption{Comparison of mean-variance relationship between WGS pool (blue) and IDT-RR pool (orange). Mean count by exon given on horizontal axis; variance of exon counts given on horizontal axis. Dotted lines show the ordinary least-squares fit. Lines above plot show the distribution of mean values; lines to the right of the plot show the distribution of variance values.}
\end{figure}

\newpage
\section{ExomeDepth selection}

<<edSelection,fig.width=3.34,fig.height=2.5>>=
pltSubjectStatByPool("medIntMolCount", ylab = "Median count per exon")
addfiglab("A")
pltSubjectStatByPool("overallPhi", ylab = "Overdispersion (phi)")
addfiglab("B")
pltSubjectStatByPool("propSelected", ylab = "Proportion of controls selected")
addfiglab("C")
pltSubjectStatByPool("nSelected", ylab = "Number of controls selected")
addfiglab("D")
@

\begin{figure}[H]
  \centering
  \includegraphics[]{figures-edSelection-1.pdf}%
  \includegraphics[]{figures-edSelection-2.pdf}
  \includegraphics[]{figures-edSelection-3.pdf}%
  \includegraphics[]{figures-edSelection-4.pdf}
  \caption{manuscript figure}
\end{figure}

\newpage
\section{Comparing calls on simulation study}

<<simResTbl,results='markup'>>=
data(simRes)
procSimRes <- lapply(simRes, function(x) procRes(x$clpRes))

simResTbl <- lapply(procSimRes,
                    function(x) x$mnDat[ , .(mcc, tpr, fdr), keyby = dep])
simResTbl <- Reduce(merge, simResTbl)
setnames(simResTbl,
         c("dep",
           "mcMCC", "mcTPR", "mcFDR",  ## mcCNV
           "edMCC", "edTPR", "edFDR",  ## ExomeDepthDefault
           "ebMCC", "ebTPR", "ebFDR")) ## ExomeDepthBest
setcolorder(simResTbl,
            c("dep", "mcMCC", "edMCC", "ebMCC", "mcTPR",
              "edTPR", "ebTPR", "mcFDR", "edFDR", "ebFDR"))
simResTbl <- simResTbl[ , lapply(.SD, signif, 3), by = dep]
simResTbl
@


<<simPlts,fig.width=2.25,fig.height=2.25>>=
pltStatCompare(xRes = procSimRes$ExomeDepthDefault, yRes = procSimRes$mcCNV,
               stat = "mcc", xlab = "ExomeDepth (default)", ylab = "mcCNV")
addfiglab("A")
pltStatCompare(xRes = procSimRes$ExomeDepthDefault, yRes = procSimRes$mcCNV,
               stat = "tpr", xlab = "ExomeDepth (default)", ylab = "mcCNV")
addfiglab("B")
pltStatCompare(xRes = procSimRes$ExomeDepthDefault, yRes = procSimRes$mcCNV,
               stat = "fdr", xlab = "ExomeDepth (default)", ylab = "mcCNV")
addfiglab("C")
pltStatCompare(xRes = procSimRes$ExomeDepthBest, yRes = procSimRes$mcCNV,
               stat = "mcc", xlab = "ExomeDepth (correct)", ylab = "mcCNV")
addfiglab("D")
pltStatCompare(xRes = procSimRes$ExomeDepthBest, yRes = procSimRes$mcCNV,
               stat = "tpr", xlab = "ExomeDepth (correct)", ylab = "mcCNV")
addfiglab("E")
pltStatCompare(xRes = procSimRes$ExomeDepthBest, yRes = procSimRes$mcCNV,
               stat = "fdr", xlab = "ExomeDepth (correct)", ylab = "mcCNV")
addfiglab("F")
@

\begin{figure}[H]
  \centering
  \includegraphics[]{figures-simPlts-1.pdf}%
  \includegraphics[]{figures-simPlts-2.pdf}%
  \includegraphics[]{figures-simPlts-3.pdf}
  \includegraphics[]{figures-simPlts-4.pdf}%
  \includegraphics[]{figures-simPlts-5.pdf}%
  \includegraphics[]{figures-simPlts-6.pdf}
  \caption{}
\end{figure}

\newpage
\section{Comparing calls on WGS pool}

<<wgsCallBySbj,results='markup'>>=
data(wgsPoolCalls)
mergeAll <- function(x, y) merge(x, y, all = TRUE)
wgs <- Reduce(mergeAll, wgsPoolCalls)
data(intAgl)
xpandInt <- function(int, sbjVec) {
  lst <- vector(mode = "list", length = length(sbjVec))
  names(lst) <- sbjVec
  for (s in sbjVec) {
    lst[[s]] <- copy(int)
    lst[[s]][ , subject := s]
  }
  rbindlist(lst)
}
wgsAgl <- xpandInt(intAgl, wgs[ , unique(subject)])
setkeyv(wgsAgl, key(wgs))
wgs <- wgs[wgsAgl]
rm(wgsAgl)
wgs <- wgs[!(rlcr),
           .(mcDup = !is.na(passFilter) & CN > 1,
             edDup = !is.na(type) & type == "duplication",
             wgDup = !is.na(erds) & !is.na(cnvpytor) & erds == "dup",
             mcDel = !is.na(passFilter) & CN < 1,
             edDel = !is.na(type) & type == "deletion",
             wgDel = !is.na(erds) & !is.na(cnvpytor) & erds == "del"),
           by = .(subject, seqnames, start, end)]
wgs[ , mc := mcDup | mcDel]
wgs[ , ed := edDup | edDel]
wgs[ , wg := wgDup | wgDel]
setcolorder(wgs, c(key(wgs), 'mc', 'ed', 'wg'))
wgsCallBySbj <- wgs[ , lapply(.SD, sum), .SDcols = is.logical, by = subject]
wgsCallBySbj
@

<<callByVarLen,results='markup'>>=
wgs[ ,
    c("mcRunID", "edRunID", "wgRunID") :=
      .(paste(subject, seqnames, rleid(mc), sep = ":"),
        paste(subject, seqnames, rleid(ed), sep = ":"),
        paste(subject, seqnames, rleid(wg), sep = ":")),
    by = .(subject, seqnames)]
wgs[!(mc), mcRunID := NA_character_]
wgs[!(ed), edRunID := NA_character_]
wgs[!(wg), wgRunID := NA_character_]
wgs[(mc), mcVarLen := .N, by = .(mcRunID)]
wgs[(ed), edVarLen := .N, by = .(edRunID)]
wgs[(wg), wgVarLen := .N, by = .(wgRunID)]

## Count number of variants by variant length for each algorithm
mergeAll <- function(x, y) merge(x, y, all = TRUE)
wgs[!subject %in% c("NCG_00790", "NCG_00851"), {
  lst <- list(.SD[!is.na(mcVarLen),
                  .(mc = length(unique(mcRunID))),
                  by = .(varLen = pmin(mcVarLen, 10))],
              .SD[!is.na(edVarLen),
                  .(ed = length(unique(edRunID))),
                  by = .(varLen = pmin(edVarLen, 10))],
              .SD[!is.na(wgVarLen),
                  .(wg = length(unique(wgRunID))),
                  by = .(varLen = pmin(wgVarLen, 10))])
  Reduce(mergeAll, lst)
}]

calcOverlap <- function(vl, exclude = c("NCG_00790", "NCG_00851")) {
  mc <- wgs[!subject %in% exclude][pmin(mcVarLen, 10) == vl]
  mc <- mc[ , .(wg = any(wg), ed = any(ed)), by = .(mcRunID)]
  mc <- mc[ , .(vl = vl, prd = "mc", wg = sum(wg)/.N, ed = sum(ed)/.N)]
  mc <- melt(mc, id.vars = c("vl", "prd"))

  ed <- wgs[!subject %in% exclude][pmin(edVarLen, 10) == vl]
  ed <- ed[ , .(wg = any(wg), mc = any(mc)), by = .(edRunID)]
  ed <- ed[ , .(vl = vl, prd = "ed", wg = sum(wg)/.N, mc = sum(mc)/.N)]
  ed <- melt(ed, id.vars = c("vl", "prd"))

  wg <- wgs[!subject %in% exclude][pmin(wgVarLen, 10) == vl]
  wg <- wg[ , .(mc = any(mc), ed = any(ed)), by = .(wgRunID)]
  wg <- wg[ , .(vl = vl, prd = "wg", mc = sum(mc)/.N, ed = sum(ed)/.N)]
  wg <- melt(wg, id.vars = c("vl", "prd"))

  res <- rbindlist(list(mc, ed, wg))
  res[ , .(vl, prd, tst = as.character(variable), pct = round(value, 3))][]
}
## Percentage of calls predicted (prd) found in the other algorithms (tst)
## by variant length (vl)
callByVarLen <- rbindlist(lapply(1:10, calcOverlap))[order(vl, prd, tst)]
cbind(callByVarLen[1:30], callByVarLen[31:60])
@

<<predMetrics, results='markup'>>=
pmLst <- list()
pmLst$mc <- with(wgs, evalPred(mc, wg))
pmLst$ed <- with(wgs, evalPred(ed, wg))
pmLst$mcSub <- with(wgs[!grepl("790|851", subject)], evalPred(mc, wg))
pmLst$edSub <- with(wgs[!grepl("790|851", subject)], evalPred(ed, wg))
pmLst$mcDup <- with(wgs, evalPred(mcDup, wgDup))
pmLst$edDup <- with(wgs, evalPred(edDup, wgDup))
pmLst$mcSubDup <- with(wgs[!grepl("790|851", subject)],
                       evalPred(mcDup, wgDup))
pmLst$edSubDup <- with(wgs[!grepl("790|851", subject)],
                       evalPred(edDup, wgDup))
pmLst$mcDel <- with(wgs, evalPred(mcDel, wgDel))
pmLst$edDel <- with(wgs, evalPred(edDel, wgDel))
pmLst$mcSubDel <- with(wgs[!grepl("790|851", subject)],
                       evalPred(mcDel, wgDel))
pmLst$edSubDel <- with(wgs[!grepl("790|851", subject)],
                       evalPred(edDel, wgDel))
predMetrics <- as.data.table(do.call(rbind, pmLst), keep.rownames = "PredSet")
predMetrics
@

\newpage
<<vennDiag, fig.width=3.38>>=
ctsAll <- euler(wgs[ , .(mc, ed, wg)])
ctsSub <- euler(wgs[!grepl("790|851", subject), .(mc, ed, wg)])
ctsAllDup <- euler(wgs[ , .(mcDup, edDup, wgDup)])
ctsSubDup <- euler(wgs[!grepl("790|851", subject), .(mcDup, edDup, wgDup)])
ctsAllDel <- euler(wgs[ , .(mcDel, edDel, wgDel)])
ctsSubDel <- euler(wgs[!grepl("790|851", subject), .(mcDel, edDel, wgDel)])
eulerr_options(fills = list(fill = c("#E9E9E9", "#7F7FC4", "#FFC57F")),
               quantities = list(cex = 0.5))
gridFigLab <- function(lab) {
  grid.text(lab, x = 0, y = 1, hjust = 0, vjust = 1, gp = gpar(font = 2))
}
plot(ctsSubDup, quantities = TRUE, labels = FALSE, main = "")
gridFigLab("A")
grid.text("DUPLICATIONS", x = 0.5, y = 0.9)
plot(ctsSubDel, quantities = TRUE, labels = FALSE, main = "")
gridFigLab("B")
grid.text("DELETIONS", x = 0.5, y = 0.9)
plot(ctsAllDup, quantities = TRUE, labels = FALSE, main = "")
gridFigLab("C")
grid.text("DUPLICATIONS", x = 0.5, y = 0.9)
plot(ctsAllDel, quantities = TRUE, labels = FALSE, main = "")
gridFigLab("D")
grid.text("DELETIONS", x = 0.5, y = 0.9)
@

<<vennDiagLgnd, fig.width=6.76, fig.height=0.5>>=
par(mar = rep(0, 4))
plot.new()
legend(x = "center",
       legend = c("MC", "ED", "WG"),
       fill = c("#E9E9E9", "#7F7FC4", "#FFC57F"),
       horiz = TRUE,
       bty = "n")
@

\begin{figure}[H]
  \centering
  \includegraphics[]{figures-vennDiag-1.pdf}%
  \includegraphics[]{figures-vennDiag-2.pdf}
  \includegraphics[]{figures-vennDiag-3.pdf}%
  \includegraphics[]{figures-vennDiag-4.pdf}
  \includegraphics[]{figures-vennDiagLgnd-1.pdf}
  \caption{(A-B) included in manuscript; (C-D) show the concordance of duplications and deletions for the whole WGS pool. mcCNV calls in gray; ExomeDepth calls in blue; ERDS/cnvpytor calls in orange.}
\end{figure}

\section{Slurm scripts to perform simulation study}

\subsection{Create count objects}

<<eval=FALSE,code=readLines("../inst/slurmScripts/varDepthCounts.R"),cache=FALSE>>=
@

\subsection{Run mcCNV on count objects}

<<eval=FALSE,code=readLines("../inst/slurmScripts/varDepthMcCalls.R"),cache=FALSE>>=
@

\subsection{Run ExomeDepth with default parameters on count objects}

<<eval=FALSE,code=readLines("../inst/slurmScripts/varDepthEdDefaultCalls.R"),cache=FALSE>>=
@

\subsection{Run ExomeDepth with simulation-matched parameters on count objects}

<<eval=FALSE,code=readLines("../inst/slurmScripts/varDepthEdBestCalls.R"),cache=FALSE>>=
@

\section{Snakemake notes}

For the Snakemake files to run, the files must be organized into a specific directory structure.
Within the exome analysis directory, pools are identified by the following structure:

\begin{quote}
\texttt{poolName/inputs/sampleName/laneID/R1.fastq.gz} \newline
\texttt{poolName/inputs/sampleName/laneID/R2.fastq.gz}
\end{quote}

Runs within the same `sampleName' will be merged into a single BAM file.
For example, the following shows the files for the NCG\_00790 sample within the WGS pool.

<<cache=FALSE>>=
# WGS/inputs/NCG_00790/
# ├── 190522_UNC41-A00434_0034_AHKL7YDSXX-GATGAATC_S6_L001
#     ├── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L001_R1_001.fastq.gz
#     └── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L001_R2_001.fastq.gz
# ├── 190522_UNC41-A00434_0034_AHKL7YDSXX-GATGAATC_S6_L002
#     ├── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L002_R1_001.fastq.gz
#     └── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L002_R2_001.fastq.gz
# ├── 190522_UNC41-A00434_0034_AHKL7YDSXX-GATGAATC_S6_L003
#     ├── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L003_R1_001.fastq.gz
#     └── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L003_R2_001.fastq.gz
# ├── 190830_UNC41-A00434_0050_AHCLVLDRXX-GATGAATC_S6_L001
#     ├── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L001_R1_001.fastq.gz
#     └── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L001_R2_001.fastq.gz
# └── 190830_UNC41-A00434_0050_AHCLVLDRXX-GATGAATC_S6_L002
#     ├── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L002_R1_001.fastq.gz
#     └── NCG_00790-CNV_Exome_XT2_GATGAATC_S6_L002_R2_001.fastq.gz

@

The genome file follows the same convention, but simply requires \texttt{inputs} and samples are not subdivided by pool.

The provided config and cluster files will need to be updated to match the cluster envrionment used; they are provided as were used as a guide.
The following shows a paired-down directory structure for the exome analysis; note the symlink to `target.intervals' within the pool folder.
The `target.intervals' file should point to a .RDS object with a valid mcCNV interval object (see \texttt{?mcCNV::cnvValidInterval}).

<<cache=FALSE>>=
# wesAnalysis/
# ├── cluster.json
# ├── config.yaml
# ├── envs
#     └── mcCNV.yaml
# ├── runme.snakemake
# ├── scratch
# ├── scripts
#     ├── aggCalls.R
#     ├── callCN.R
#     ├── exomeDepth.R
#     └── getCounts.R
# ├── Snakefile
# ├── slurmOut
# └── WGS
#     ├── inputs
#     └── target.intervals -> path to interval .RDS object
@

For the genome analysis, ERDS will have to be installed manually prior to running the pipeline.
We used the following shell script, but have zero expecations it will work within all environments.

<<eval=FALSE,code=readLines("../inst/snakemakeScripts/wgsAnalysis/getAndBuildERDS.sh"),highlight=FALSE,cache=FALSE>>=
@

\section{Snakemake file for exome anlaysis}

Note, Snakemake file and all accessory files contained within the filer2020A package `inst' directory.

<<eval=FALSE,code=readLines("../inst/snakemakeScripts/wesAnalysis/Snakefile"),highlight=FALSE,cache=FALSE>>=
@

\section{Snakemake file for genome anlaysis}

Note, Snakemake file and all accessory files contained within the filer2020A package `inst' directory.

<<eval=FALSE,code=readLines("../inst/snakemakeScripts/wgsAnalysis/Snakefile"),highlight=FALSE,cache=FALSE>>=
@


\end{document}
